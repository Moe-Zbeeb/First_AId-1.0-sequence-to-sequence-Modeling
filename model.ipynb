{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mohammad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random \n",
    "import tensorflow as tf\n",
    "import json \n",
    "#impoort the split \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "#import keras classifier   \n",
    "#IMPORY SGD \n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/home/mohammad/Desktop/First_AId-1.0-sequence-to-sequence-/intents (2).json\") as file:\n",
    "    data = json.load(file)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define preprocessing functions\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "# Initialize lists for words, labels, training data, and output\n",
    "words = []\n",
    "labels = []\n",
    "training_data = []\n",
    "output_data = []\n",
    "\n",
    "# Tokenize and stem each pattern, and prepare training data and output\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        tokens = tokenize(pattern)\n",
    "        words.extend(tokens)\n",
    "        training_data.append(tokens)\n",
    "        output_data.append(intent[\"tag\"])\n",
    "\n",
    "        if intent[\"tag\"] not in labels:\n",
    "            labels.append(intent[\"tag\"])\n",
    "\n",
    "# Stem and lowercase words, remove duplicates, and sort\n",
    "words = sorted(list(set([stem(word) for word in words if word != \"?\"])))\n",
    "labels = sorted(labels)\n",
    "\n",
    "# Initialize empty output rows\n",
    "out_empty = [0] * len(labels)\n",
    "\n",
    "# Prepare training and output arrays\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, doc in enumerate(training_data):\n",
    "    bag = []\n",
    "\n",
    "    # Stem and lowercase words in the pattern\n",
    "    tokens = [stem(word) for word in doc]\n",
    "\n",
    "    # Create bag of words\n",
    "    for word in words:\n",
    "        bag.append(1) if word in tokens else bag.append(0)\n",
    "\n",
    "    # Create output row\n",
    "    output_row = list(out_empty)\n",
    "    output_row[labels.index(output_data[idx])] = 1\n",
    "\n",
    "    X.append(bag)\n",
    "    y.append(output_row)\n",
    "\n",
    "# Conve\n",
    "training = np.array(X)\n",
    "output = np.array(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mohammad/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Train on 1650 samples\n",
      "Epoch 1/350\n",
      "1650/1650 [==============================] - 0s 185us/sample - loss: 6.2570 - acc: 0.0127\n",
      "Epoch 2/350\n",
      "1650/1650 [==============================] - 0s 136us/sample - loss: 5.8801 - acc: 0.0188\n",
      "Epoch 3/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 5.5562 - acc: 0.0448\n",
      "Epoch 4/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 5.1832 - acc: 0.0927\n",
      "Epoch 5/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 4.6941 - acc: 0.1448\n",
      "Epoch 6/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 4.1621 - acc: 0.1770\n",
      "Epoch 7/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 3.6869 - acc: 0.2339\n",
      "Epoch 8/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 3.2574 - acc: 0.2933\n",
      "Epoch 9/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 2.8890 - acc: 0.3503\n",
      "Epoch 10/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 2.5632 - acc: 0.4194\n",
      "Epoch 11/350\n",
      "1650/1650 [==============================] - 0s 132us/sample - loss: 2.3537 - acc: 0.4448\n",
      "Epoch 12/350\n",
      "1650/1650 [==============================] - 0s 129us/sample - loss: 2.1005 - acc: 0.5145\n",
      "Epoch 13/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 1.9020 - acc: 0.5394\n",
      "Epoch 14/350\n",
      "1650/1650 [==============================] - 0s 115us/sample - loss: 1.7420 - acc: 0.5703\n",
      "Epoch 15/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 1.5386 - acc: 0.6091\n",
      "Epoch 16/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 1.4498 - acc: 0.6176\n",
      "Epoch 17/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 1.2988 - acc: 0.6545\n",
      "Epoch 18/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 1.2025 - acc: 0.6758\n",
      "Epoch 19/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 1.0948 - acc: 0.6952\n",
      "Epoch 20/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 1.0315 - acc: 0.7200\n",
      "Epoch 21/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.9168 - acc: 0.7382\n",
      "Epoch 22/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.8527 - acc: 0.7636\n",
      "Epoch 23/350\n",
      "1650/1650 [==============================] - 0s 115us/sample - loss: 0.7967 - acc: 0.7824\n",
      "Epoch 24/350\n",
      "1650/1650 [==============================] - 0s 138us/sample - loss: 0.7855 - acc: 0.7752\n",
      "Epoch 25/350\n",
      "1650/1650 [==============================] - 0s 142us/sample - loss: 0.7562 - acc: 0.7818\n",
      "Epoch 26/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.6412 - acc: 0.8152\n",
      "Epoch 27/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.6125 - acc: 0.8127\n",
      "Epoch 28/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.6124 - acc: 0.8297\n",
      "Epoch 29/350\n",
      "1650/1650 [==============================] - 0s 137us/sample - loss: 0.5639 - acc: 0.8242\n",
      "Epoch 30/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.5352 - acc: 0.8503\n",
      "Epoch 31/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.5345 - acc: 0.8394\n",
      "Epoch 32/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.5450 - acc: 0.8358\n",
      "Epoch 33/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.4765 - acc: 0.8533\n",
      "Epoch 34/350\n",
      "1650/1650 [==============================] - 0s 146us/sample - loss: 0.4779 - acc: 0.8582\n",
      "Epoch 35/350\n",
      "1650/1650 [==============================] - 0s 135us/sample - loss: 0.4263 - acc: 0.8721\n",
      "Epoch 36/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.4142 - acc: 0.8770\n",
      "Epoch 37/350\n",
      "1650/1650 [==============================] - 0s 115us/sample - loss: 0.4163 - acc: 0.8745\n",
      "Epoch 38/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.4040 - acc: 0.8691\n",
      "Epoch 39/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.3807 - acc: 0.8855\n",
      "Epoch 40/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.3835 - acc: 0.8885\n",
      "Epoch 41/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.3620 - acc: 0.8891\n",
      "Epoch 42/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.3042 - acc: 0.9036\n",
      "Epoch 43/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.3182 - acc: 0.9042\n",
      "Epoch 44/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.3186 - acc: 0.8994\n",
      "Epoch 45/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.2964 - acc: 0.9055\n",
      "Epoch 46/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.3154 - acc: 0.9067\n",
      "Epoch 47/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.2949 - acc: 0.9127\n",
      "Epoch 48/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.2746 - acc: 0.9109\n",
      "Epoch 49/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.2733 - acc: 0.9139\n",
      "Epoch 50/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.2541 - acc: 0.9297\n",
      "Epoch 51/350\n",
      "1650/1650 [==============================] - 0s 115us/sample - loss: 0.2397 - acc: 0.9212\n",
      "Epoch 52/350\n",
      "1650/1650 [==============================] - 0s 114us/sample - loss: 0.2371 - acc: 0.9242\n",
      "Epoch 53/350\n",
      "1650/1650 [==============================] - 0s 114us/sample - loss: 0.2331 - acc: 0.9236\n",
      "Epoch 54/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.2518 - acc: 0.9121\n",
      "Epoch 55/350\n",
      "1650/1650 [==============================] - 0s 114us/sample - loss: 0.2447 - acc: 0.9224\n",
      "Epoch 56/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.2090 - acc: 0.9309\n",
      "Epoch 57/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.2639 - acc: 0.9194\n",
      "Epoch 58/350\n",
      "1650/1650 [==============================] - 0s 133us/sample - loss: 0.2369 - acc: 0.9230\n",
      "Epoch 59/350\n",
      "1650/1650 [==============================] - 0s 113us/sample - loss: 0.2402 - acc: 0.9273\n",
      "Epoch 60/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.2330 - acc: 0.9224\n",
      "Epoch 61/350\n",
      "1650/1650 [==============================] - 0s 115us/sample - loss: 0.2315 - acc: 0.9273\n",
      "Epoch 62/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.2230 - acc: 0.9315\n",
      "Epoch 63/350\n",
      "1650/1650 [==============================] - 0s 113us/sample - loss: 0.2275 - acc: 0.9309\n",
      "Epoch 64/350\n",
      "1650/1650 [==============================] - 0s 115us/sample - loss: 0.1973 - acc: 0.9364\n",
      "Epoch 65/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.2370 - acc: 0.9273\n",
      "Epoch 66/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.2122 - acc: 0.9291\n",
      "Epoch 67/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.2241 - acc: 0.9352\n",
      "Epoch 68/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.2262 - acc: 0.9261\n",
      "Epoch 69/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.1926 - acc: 0.9370\n",
      "Epoch 70/350\n",
      "1650/1650 [==============================] - 0s 114us/sample - loss: 0.1823 - acc: 0.9388\n",
      "Epoch 71/350\n",
      "1650/1650 [==============================] - 0s 115us/sample - loss: 0.2117 - acc: 0.9339\n",
      "Epoch 72/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.1753 - acc: 0.9430\n",
      "Epoch 73/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.1689 - acc: 0.9430\n",
      "Epoch 74/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1923 - acc: 0.9309\n",
      "Epoch 75/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.1971 - acc: 0.9382\n",
      "Epoch 76/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1765 - acc: 0.9448\n",
      "Epoch 77/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.1824 - acc: 0.9406\n",
      "Epoch 78/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.1716 - acc: 0.9436\n",
      "Epoch 79/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.1733 - acc: 0.9376\n",
      "Epoch 80/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.2101 - acc: 0.9248\n",
      "Epoch 81/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.1572 - acc: 0.9467\n",
      "Epoch 82/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1460 - acc: 0.9527\n",
      "Epoch 83/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.2079 - acc: 0.9333\n",
      "Epoch 84/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1826 - acc: 0.9321\n",
      "Epoch 85/350\n",
      "1650/1650 [==============================] - 0s 145us/sample - loss: 0.1718 - acc: 0.9436\n",
      "Epoch 86/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.1801 - acc: 0.9418\n",
      "Epoch 87/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.1581 - acc: 0.9461\n",
      "Epoch 88/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1651 - acc: 0.9485\n",
      "Epoch 89/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.1479 - acc: 0.9485\n",
      "Epoch 90/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1582 - acc: 0.9436\n",
      "Epoch 91/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.1587 - acc: 0.9430\n",
      "Epoch 92/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1399 - acc: 0.9509\n",
      "Epoch 93/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1551 - acc: 0.9509\n",
      "Epoch 94/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.1631 - acc: 0.9364\n",
      "Epoch 95/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1581 - acc: 0.9400\n",
      "Epoch 96/350\n",
      "1650/1650 [==============================] - 0s 133us/sample - loss: 0.1422 - acc: 0.9473\n",
      "Epoch 97/350\n",
      "1650/1650 [==============================] - 0s 173us/sample - loss: 0.1610 - acc: 0.9448\n",
      "Epoch 98/350\n",
      "1650/1650 [==============================] - 0s 140us/sample - loss: 0.1841 - acc: 0.9327\n",
      "Epoch 99/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1587 - acc: 0.9479\n",
      "Epoch 100/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1412 - acc: 0.9539\n",
      "Epoch 101/350\n",
      "1650/1650 [==============================] - 0s 137us/sample - loss: 0.1491 - acc: 0.9503\n",
      "Epoch 102/350\n",
      "1650/1650 [==============================] - 0s 153us/sample - loss: 0.1462 - acc: 0.9491\n",
      "Epoch 103/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1428 - acc: 0.9479\n",
      "Epoch 104/350\n",
      "1650/1650 [==============================] - 0s 127us/sample - loss: 0.1355 - acc: 0.9539\n",
      "Epoch 105/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1343 - acc: 0.9497\n",
      "Epoch 106/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1500 - acc: 0.9467\n",
      "Epoch 107/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1701 - acc: 0.9406\n",
      "Epoch 108/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1422 - acc: 0.9527\n",
      "Epoch 109/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1368 - acc: 0.9509\n",
      "Epoch 110/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1257 - acc: 0.9600\n",
      "Epoch 111/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1339 - acc: 0.9521\n",
      "Epoch 112/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1388 - acc: 0.9430\n",
      "Epoch 113/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1334 - acc: 0.9497\n",
      "Epoch 114/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1459 - acc: 0.9473\n",
      "Epoch 115/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.1496 - acc: 0.9467\n",
      "Epoch 116/350\n",
      "1650/1650 [==============================] - 0s 131us/sample - loss: 0.1750 - acc: 0.9400\n",
      "Epoch 117/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.1632 - acc: 0.9461\n",
      "Epoch 118/350\n",
      "1650/1650 [==============================] - 0s 132us/sample - loss: 0.1512 - acc: 0.9406\n",
      "Epoch 119/350\n",
      "1650/1650 [==============================] - 0s 140us/sample - loss: 0.1568 - acc: 0.9436\n",
      "Epoch 120/350\n",
      "1650/1650 [==============================] - 0s 151us/sample - loss: 0.1400 - acc: 0.9497\n",
      "Epoch 121/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.1217 - acc: 0.9564\n",
      "Epoch 122/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1290 - acc: 0.9527\n",
      "Epoch 123/350\n",
      "1650/1650 [==============================] - 0s 131us/sample - loss: 0.1411 - acc: 0.9503\n",
      "Epoch 124/350\n",
      "1650/1650 [==============================] - 0s 129us/sample - loss: 0.1433 - acc: 0.9485\n",
      "Epoch 125/350\n",
      "1650/1650 [==============================] - 0s 130us/sample - loss: 0.1236 - acc: 0.9552\n",
      "Epoch 126/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.1292 - acc: 0.9564\n",
      "Epoch 127/350\n",
      "1650/1650 [==============================] - 0s 139us/sample - loss: 0.1347 - acc: 0.9473\n",
      "Epoch 128/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1648 - acc: 0.9370\n",
      "Epoch 129/350\n",
      "1650/1650 [==============================] - 0s 139us/sample - loss: 0.1617 - acc: 0.9418\n",
      "Epoch 130/350\n",
      "1650/1650 [==============================] - 0s 132us/sample - loss: 0.1433 - acc: 0.9491\n",
      "Epoch 131/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1270 - acc: 0.9539\n",
      "Epoch 132/350\n",
      "1650/1650 [==============================] - 0s 129us/sample - loss: 0.1427 - acc: 0.9485\n",
      "Epoch 133/350\n",
      "1650/1650 [==============================] - 0s 151us/sample - loss: 0.1349 - acc: 0.9515\n",
      "Epoch 134/350\n",
      "1650/1650 [==============================] - 0s 233us/sample - loss: 0.1268 - acc: 0.9545\n",
      "Epoch 135/350\n",
      "1650/1650 [==============================] - 0s 178us/sample - loss: 0.1289 - acc: 0.9588\n",
      "Epoch 136/350\n",
      "1650/1650 [==============================] - 0s 132us/sample - loss: 0.1320 - acc: 0.9503\n",
      "Epoch 137/350\n",
      "1650/1650 [==============================] - 0s 138us/sample - loss: 0.1330 - acc: 0.9503\n",
      "Epoch 138/350\n",
      "1650/1650 [==============================] - 0s 147us/sample - loss: 0.1330 - acc: 0.9570\n",
      "Epoch 139/350\n",
      "1650/1650 [==============================] - 0s 134us/sample - loss: 0.1447 - acc: 0.9503\n",
      "Epoch 140/350\n",
      "1650/1650 [==============================] - 0s 141us/sample - loss: 0.1183 - acc: 0.9558\n",
      "Epoch 141/350\n",
      "1650/1650 [==============================] - 0s 142us/sample - loss: 0.1093 - acc: 0.9612\n",
      "Epoch 142/350\n",
      "1650/1650 [==============================] - 0s 132us/sample - loss: 0.1277 - acc: 0.9533\n",
      "Epoch 143/350\n",
      "1650/1650 [==============================] - 0s 146us/sample - loss: 0.1189 - acc: 0.9539\n",
      "Epoch 144/350\n",
      "1650/1650 [==============================] - 0s 145us/sample - loss: 0.1171 - acc: 0.9570\n",
      "Epoch 145/350\n",
      "1650/1650 [==============================] - 0s 141us/sample - loss: 0.1255 - acc: 0.9564\n",
      "Epoch 146/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1195 - acc: 0.9545\n",
      "Epoch 147/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.1183 - acc: 0.9497\n",
      "Epoch 148/350\n",
      "1650/1650 [==============================] - 0s 135us/sample - loss: 0.1099 - acc: 0.9606\n",
      "Epoch 149/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.1256 - acc: 0.9564\n",
      "Epoch 150/350\n",
      "1650/1650 [==============================] - 0s 139us/sample - loss: 0.1281 - acc: 0.9497\n",
      "Epoch 151/350\n",
      "1650/1650 [==============================] - 0s 139us/sample - loss: 0.1133 - acc: 0.9618\n",
      "Epoch 152/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.1175 - acc: 0.9558\n",
      "Epoch 153/350\n",
      "1650/1650 [==============================] - 0s 139us/sample - loss: 0.1082 - acc: 0.9600\n",
      "Epoch 154/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1029 - acc: 0.9570\n",
      "Epoch 155/350\n",
      "1650/1650 [==============================] - 0s 137us/sample - loss: 0.1031 - acc: 0.9558\n",
      "Epoch 156/350\n",
      "1650/1650 [==============================] - 0s 131us/sample - loss: 0.1146 - acc: 0.9509\n",
      "Epoch 157/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1100 - acc: 0.9606\n",
      "Epoch 158/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1082 - acc: 0.9545\n",
      "Epoch 159/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.1039 - acc: 0.9582\n",
      "Epoch 160/350\n",
      "1650/1650 [==============================] - 0s 162us/sample - loss: 0.1127 - acc: 0.9564\n",
      "Epoch 161/350\n",
      "1650/1650 [==============================] - 0s 137us/sample - loss: 0.1056 - acc: 0.9588\n",
      "Epoch 162/350\n",
      "1650/1650 [==============================] - 0s 135us/sample - loss: 0.1494 - acc: 0.9448\n",
      "Epoch 163/350\n",
      "1650/1650 [==============================] - 0s 127us/sample - loss: 0.1107 - acc: 0.9558\n",
      "Epoch 164/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1151 - acc: 0.9570\n",
      "Epoch 165/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.1009 - acc: 0.9618\n",
      "Epoch 166/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1181 - acc: 0.9552\n",
      "Epoch 167/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1259 - acc: 0.9545\n",
      "Epoch 168/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1099 - acc: 0.9570\n",
      "Epoch 169/350\n",
      "1650/1650 [==============================] - 0s 143us/sample - loss: 0.1121 - acc: 0.9570\n",
      "Epoch 170/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1296 - acc: 0.9515\n",
      "Epoch 171/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1058 - acc: 0.9582\n",
      "Epoch 172/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1438 - acc: 0.9467\n",
      "Epoch 173/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1199 - acc: 0.9545\n",
      "Epoch 174/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1096 - acc: 0.9594\n",
      "Epoch 175/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1160 - acc: 0.9545\n",
      "Epoch 176/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1394 - acc: 0.9509\n",
      "Epoch 177/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1112 - acc: 0.9558\n",
      "Epoch 178/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1271 - acc: 0.9558\n",
      "Epoch 179/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1129 - acc: 0.9564\n",
      "Epoch 180/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1052 - acc: 0.9564\n",
      "Epoch 181/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.0948 - acc: 0.9606\n",
      "Epoch 182/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.1064 - acc: 0.9545\n",
      "Epoch 183/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0941 - acc: 0.9600\n",
      "Epoch 184/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1047 - acc: 0.9594\n",
      "Epoch 185/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.0991 - acc: 0.9606\n",
      "Epoch 186/350\n",
      "1650/1650 [==============================] - 0s 168us/sample - loss: 0.1331 - acc: 0.9521\n",
      "Epoch 187/350\n",
      "1650/1650 [==============================] - 0s 127us/sample - loss: 0.1075 - acc: 0.9545\n",
      "Epoch 188/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1470 - acc: 0.9473\n",
      "Epoch 189/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1204 - acc: 0.9533\n",
      "Epoch 190/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1154 - acc: 0.9594\n",
      "Epoch 191/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1184 - acc: 0.9539\n",
      "Epoch 192/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1083 - acc: 0.9558\n",
      "Epoch 193/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1060 - acc: 0.9594\n",
      "Epoch 194/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1307 - acc: 0.9552\n",
      "Epoch 195/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.0959 - acc: 0.9612\n",
      "Epoch 196/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1058 - acc: 0.9552\n",
      "Epoch 197/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1081 - acc: 0.9576\n",
      "Epoch 198/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1267 - acc: 0.9545\n",
      "Epoch 199/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1095 - acc: 0.9521\n",
      "Epoch 200/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1184 - acc: 0.9545\n",
      "Epoch 201/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.0906 - acc: 0.9606\n",
      "Epoch 202/350\n",
      "1650/1650 [==============================] - 0s 139us/sample - loss: 0.0992 - acc: 0.9594\n",
      "Epoch 203/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1102 - acc: 0.9539\n",
      "Epoch 204/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.0891 - acc: 0.9661\n",
      "Epoch 205/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1124 - acc: 0.9527\n",
      "Epoch 206/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.0945 - acc: 0.9564\n",
      "Epoch 207/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0945 - acc: 0.9606\n",
      "Epoch 208/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0890 - acc: 0.9642\n",
      "Epoch 209/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1256 - acc: 0.9636\n",
      "Epoch 210/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.0942 - acc: 0.9606\n",
      "Epoch 211/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1156 - acc: 0.9509\n",
      "Epoch 212/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1307 - acc: 0.9430\n",
      "Epoch 213/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1075 - acc: 0.9527\n",
      "Epoch 214/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1021 - acc: 0.9570\n",
      "Epoch 215/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0979 - acc: 0.9612\n",
      "Epoch 216/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1056 - acc: 0.9570\n",
      "Epoch 217/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1118 - acc: 0.9558\n",
      "Epoch 218/350\n",
      "1650/1650 [==============================] - 0s 132us/sample - loss: 0.0905 - acc: 0.9636\n",
      "Epoch 219/350\n",
      "1650/1650 [==============================] - 0s 136us/sample - loss: 0.0975 - acc: 0.9576\n",
      "Epoch 220/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1016 - acc: 0.9582\n",
      "Epoch 221/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1030 - acc: 0.9642\n",
      "Epoch 222/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1141 - acc: 0.9576\n",
      "Epoch 223/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0995 - acc: 0.9618\n",
      "Epoch 224/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.0799 - acc: 0.9636\n",
      "Epoch 225/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.0929 - acc: 0.9600\n",
      "Epoch 226/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0977 - acc: 0.9600\n",
      "Epoch 227/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0907 - acc: 0.9648\n",
      "Epoch 228/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.0945 - acc: 0.9588\n",
      "Epoch 229/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.1001 - acc: 0.9564\n",
      "Epoch 230/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1101 - acc: 0.9545\n",
      "Epoch 231/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.1033 - acc: 0.9552\n",
      "Epoch 232/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.0925 - acc: 0.9624\n",
      "Epoch 233/350\n",
      "1650/1650 [==============================] - 0s 139us/sample - loss: 0.0924 - acc: 0.9600\n",
      "Epoch 234/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0953 - acc: 0.9612\n",
      "Epoch 235/350\n",
      "1650/1650 [==============================] - 0s 116us/sample - loss: 0.0906 - acc: 0.9570\n",
      "Epoch 236/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.0987 - acc: 0.9582\n",
      "Epoch 237/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1132 - acc: 0.9588\n",
      "Epoch 238/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.1045 - acc: 0.9600\n",
      "Epoch 239/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1072 - acc: 0.9594\n",
      "Epoch 240/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1039 - acc: 0.9552\n",
      "Epoch 241/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.1258 - acc: 0.9485\n",
      "Epoch 242/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1030 - acc: 0.9618\n",
      "Epoch 243/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0834 - acc: 0.9642\n",
      "Epoch 244/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.0929 - acc: 0.9600\n",
      "Epoch 245/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.0994 - acc: 0.9594\n",
      "Epoch 246/350\n",
      "1650/1650 [==============================] - 0s 127us/sample - loss: 0.1084 - acc: 0.9558\n",
      "Epoch 247/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1266 - acc: 0.9533\n",
      "Epoch 248/350\n",
      "1650/1650 [==============================] - 0s 145us/sample - loss: 0.0955 - acc: 0.9582\n",
      "Epoch 249/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1043 - acc: 0.9539\n",
      "Epoch 250/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.1132 - acc: 0.9527\n",
      "Epoch 251/350\n",
      "1650/1650 [==============================] - 0s 130us/sample - loss: 0.0977 - acc: 0.9594\n",
      "Epoch 252/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.1234 - acc: 0.9552\n",
      "Epoch 253/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1176 - acc: 0.9564\n",
      "Epoch 254/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.1105 - acc: 0.9539\n",
      "Epoch 255/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.0988 - acc: 0.9624\n",
      "Epoch 256/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.0960 - acc: 0.9588\n",
      "Epoch 257/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.1074 - acc: 0.9564\n",
      "Epoch 258/350\n",
      "1650/1650 [==============================] - 0s 132us/sample - loss: 0.0991 - acc: 0.9582\n",
      "Epoch 259/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0968 - acc: 0.9630\n",
      "Epoch 260/350\n",
      "1650/1650 [==============================] - 0s 145us/sample - loss: 0.1059 - acc: 0.9539\n",
      "Epoch 261/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1024 - acc: 0.9600\n",
      "Epoch 262/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.0862 - acc: 0.9618\n",
      "Epoch 263/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1000 - acc: 0.9600\n",
      "Epoch 264/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.0834 - acc: 0.9582\n",
      "Epoch 265/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.1153 - acc: 0.9515\n",
      "Epoch 266/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1051 - acc: 0.9594\n",
      "Epoch 267/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0965 - acc: 0.9630\n",
      "Epoch 268/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0923 - acc: 0.9642\n",
      "Epoch 269/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.0789 - acc: 0.9655\n",
      "Epoch 270/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.0883 - acc: 0.9600\n",
      "Epoch 271/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0921 - acc: 0.9576\n",
      "Epoch 272/350\n",
      "1650/1650 [==============================] - 0s 141us/sample - loss: 0.0901 - acc: 0.9642\n",
      "Epoch 273/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.0837 - acc: 0.9612\n",
      "Epoch 274/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.0887 - acc: 0.9624\n",
      "Epoch 275/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1127 - acc: 0.9570\n",
      "Epoch 276/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.1068 - acc: 0.9588\n",
      "Epoch 277/350\n",
      "1650/1650 [==============================] - 0s 134us/sample - loss: 0.1038 - acc: 0.9594\n",
      "Epoch 278/350\n",
      "1650/1650 [==============================] - 0s 130us/sample - loss: 0.1163 - acc: 0.9570\n",
      "Epoch 279/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.1024 - acc: 0.9594\n",
      "Epoch 280/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.0960 - acc: 0.9612\n",
      "Epoch 281/350\n",
      "1650/1650 [==============================] - 0s 131us/sample - loss: 0.1112 - acc: 0.9539\n",
      "Epoch 282/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.1352 - acc: 0.9503\n",
      "Epoch 283/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1180 - acc: 0.9576\n",
      "Epoch 284/350\n",
      "1650/1650 [==============================] - 0s 156us/sample - loss: 0.0880 - acc: 0.9606\n",
      "Epoch 285/350\n",
      "1650/1650 [==============================] - 0s 127us/sample - loss: 0.0803 - acc: 0.9630\n",
      "Epoch 286/350\n",
      "1650/1650 [==============================] - 0s 137us/sample - loss: 0.1039 - acc: 0.9570\n",
      "Epoch 287/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.0983 - acc: 0.9636\n",
      "Epoch 288/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0959 - acc: 0.9570\n",
      "Epoch 289/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0783 - acc: 0.9673\n",
      "Epoch 290/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0862 - acc: 0.9630\n",
      "Epoch 291/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.0966 - acc: 0.9655\n",
      "Epoch 292/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.0889 - acc: 0.9636\n",
      "Epoch 293/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.0930 - acc: 0.9636\n",
      "Epoch 294/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1100 - acc: 0.9588\n",
      "Epoch 295/350\n",
      "1650/1650 [==============================] - 0s 139us/sample - loss: 0.1209 - acc: 0.9545\n",
      "Epoch 296/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1027 - acc: 0.9624\n",
      "Epoch 297/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.1104 - acc: 0.9527\n",
      "Epoch 298/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1005 - acc: 0.9564\n",
      "Epoch 299/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.1039 - acc: 0.9582\n",
      "Epoch 300/350\n",
      "1650/1650 [==============================] - 0s 137us/sample - loss: 0.0934 - acc: 0.9588\n",
      "Epoch 301/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.0917 - acc: 0.9624\n",
      "Epoch 302/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1054 - acc: 0.9582\n",
      "Epoch 303/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.0921 - acc: 0.9600\n",
      "Epoch 304/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0985 - acc: 0.9636\n",
      "Epoch 305/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1081 - acc: 0.9594\n",
      "Epoch 306/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.0865 - acc: 0.9624\n",
      "Epoch 307/350\n",
      "1650/1650 [==============================] - 0s 136us/sample - loss: 0.0712 - acc: 0.9661\n",
      "Epoch 308/350\n",
      "1650/1650 [==============================] - 0s 160us/sample - loss: 0.1054 - acc: 0.9570\n",
      "Epoch 309/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.0974 - acc: 0.9539\n",
      "Epoch 310/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0830 - acc: 0.9679\n",
      "Epoch 311/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.0939 - acc: 0.9624\n",
      "Epoch 312/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.0902 - acc: 0.9618\n",
      "Epoch 313/350\n",
      "1650/1650 [==============================] - 0s 139us/sample - loss: 0.0906 - acc: 0.9606\n",
      "Epoch 314/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.0936 - acc: 0.9630\n",
      "Epoch 315/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0875 - acc: 0.9612\n",
      "Epoch 316/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0959 - acc: 0.9648\n",
      "Epoch 317/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0898 - acc: 0.9606\n",
      "Epoch 318/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.0717 - acc: 0.9661\n",
      "Epoch 319/350\n",
      "1650/1650 [==============================] - 0s 151us/sample - loss: 0.0720 - acc: 0.9679\n",
      "Epoch 320/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.0834 - acc: 0.9667\n",
      "Epoch 321/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.1045 - acc: 0.9576\n",
      "Epoch 322/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.0853 - acc: 0.9618\n",
      "Epoch 323/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0886 - acc: 0.9618\n",
      "Epoch 324/350\n",
      "1650/1650 [==============================] - 0s 135us/sample - loss: 0.0745 - acc: 0.9673\n",
      "Epoch 325/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.1139 - acc: 0.9576\n",
      "Epoch 326/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.0786 - acc: 0.9636\n",
      "Epoch 327/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.1138 - acc: 0.9545\n",
      "Epoch 328/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0797 - acc: 0.9642\n",
      "Epoch 329/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.0800 - acc: 0.9655\n",
      "Epoch 330/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.0955 - acc: 0.9630\n",
      "Epoch 331/350\n",
      "1650/1650 [==============================] - 0s 120us/sample - loss: 0.0915 - acc: 0.9655\n",
      "Epoch 332/350\n",
      "1650/1650 [==============================] - 0s 118us/sample - loss: 0.0856 - acc: 0.9648\n",
      "Epoch 333/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.1021 - acc: 0.9545\n",
      "Epoch 334/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.1252 - acc: 0.9509\n",
      "Epoch 335/350\n",
      "1650/1650 [==============================] - 0s 143us/sample - loss: 0.1128 - acc: 0.9618\n",
      "Epoch 336/350\n",
      "1650/1650 [==============================] - 0s 119us/sample - loss: 0.0821 - acc: 0.9624\n",
      "Epoch 337/350\n",
      "1650/1650 [==============================] - 0s 123us/sample - loss: 0.0708 - acc: 0.9667\n",
      "Epoch 338/350\n",
      "1650/1650 [==============================] - 0s 125us/sample - loss: 0.1092 - acc: 0.9594\n",
      "Epoch 339/350\n",
      "1650/1650 [==============================] - 0s 124us/sample - loss: 0.0870 - acc: 0.9624\n",
      "Epoch 340/350\n",
      "1650/1650 [==============================] - 0s 127us/sample - loss: 0.0917 - acc: 0.9618\n",
      "Epoch 341/350\n",
      "1650/1650 [==============================] - 0s 121us/sample - loss: 0.0865 - acc: 0.9636\n",
      "Epoch 342/350\n",
      "1650/1650 [==============================] - 0s 117us/sample - loss: 0.0894 - acc: 0.9594\n",
      "Epoch 343/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.1043 - acc: 0.9527\n",
      "Epoch 344/350\n",
      "1650/1650 [==============================] - 0s 122us/sample - loss: 0.0945 - acc: 0.9606\n",
      "Epoch 345/350\n",
      "1650/1650 [==============================] - 0s 138us/sample - loss: 0.1011 - acc: 0.9606\n",
      "Epoch 346/350\n",
      "1650/1650 [==============================] - 0s 128us/sample - loss: 0.0954 - acc: 0.9570\n",
      "Epoch 347/350\n",
      "1650/1650 [==============================] - 0s 131us/sample - loss: 0.1008 - acc: 0.9618\n",
      "Epoch 348/350\n",
      "1650/1650 [==============================] - 0s 129us/sample - loss: 0.0877 - acc: 0.9618\n",
      "Epoch 349/350\n",
      "1650/1650 [==============================] - 0s 133us/sample - loss: 0.0960 - acc: 0.9600\n",
      "Epoch 350/350\n",
      "1650/1650 [==============================] - 0s 126us/sample - loss: 0.0966 - acc: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f0cb6f01130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Reset the default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    # Input layer (implicit by specifying input_shape in the first Dense layer)\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(len(training[0]),)),  \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(len(output[0]), activation='softmax')\n",
    "])\n",
    "\n",
    "# Define optimizer\n",
    "sgd = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.9, use_nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )    \n",
    "\n",
    "# Fit the model\n",
    "model.fit(training, output, epochs=350, batch_size=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x7f0cb7765d00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s,words):\n",
    "\tbag = [0 for _ in range(len(words))]\n",
    "\n",
    "\n",
    "\ts_words = nltk.word_tokenize(s)\n",
    "\ts_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "\tfor se in s_words:\n",
    "\t\tfor i, w in enumerate(words):\n",
    "\t\t\tif w == se:\n",
    "\t\t\t\tbag[i] = 1\n",
    "\n",
    "\treturn numpy.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(string1):\n",
    "\n",
    "        # Preprocess input text into bag of words\n",
    "        inp_bag_of_words = bag_of_words(string1, words)\n",
    "\n",
    "        # Reshape input for model prediction\n",
    "        inp_bag_of_words = inp_bag_of_words.reshape(1, inp_bag_of_words.shape[0])\n",
    "\n",
    "        # Predict using the model\n",
    "        results = model.predict(inp_bag_of_words)[0]\n",
    "\n",
    "        results_index = numpy.argmax(results)\n",
    "        tag = labels[results_index]\n",
    "\n",
    "        if results[results_index] > 0.3:\n",
    "            for tg in data[\"intents\"]:\n",
    "                if tg['tag'] == tag:\n",
    "                    responses = tg['responses']\n",
    "            return (random.choice(responses))\n",
    "            \n",
    "\n",
    "        else:\n",
    "            return (\"I didn't get that, try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "##save the model     \n",
    "model.save('chatbot_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-c754920e6660>:6: DeprecationWarning: sipPyTypeDict() is deprecated, the extension module should use sipPyTypeDictRef() instead\n",
      "  class ChatGUI(QWidget):\n",
      "/home/mohammad/.local/lib/python3.8/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QVBoxLayout, QWidget, QTextEdit, QPushButton, QHBoxLayout\n",
    "from PyQt5.QtGui import QIcon  \n",
    "import emoji\n",
    "from PyQt5.QtCore import QTimer, QPropertyAnimation, Qt  \n",
    "class ChatGUI(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"First AId\")  \n",
    "\n",
    "        topLayout = QVBoxLayout()\n",
    "        outerLayout = QVBoxLayout()\n",
    "        bottomLayout = QHBoxLayout()\n",
    "\n",
    "        self.label = QLabel(emoji.emojize(\"      First AI \", variant=\"emoji_type\" )+'d Chatbot')  \n",
    "        self.label.setFixedSize(350, 50)\n",
    "        self.inputTextEdit = QTextEdit()  \n",
    "        self.inputTextEdit.setFixedSize(300, 50)     \n",
    "        self.inputTextEdit.setPlaceholderText(\"Type your message here...\")  # Set placeholder text\n",
    "        self.outputTextEdit = QTextEdit()   \n",
    "        self.outputTextEdit.setReadOnly(True)   \n",
    "        self.outputTextEdit.setFixedSize(350, 300)\n",
    "\n",
    "        self.sendButton = QPushButton(\"\")  \n",
    "        self.sendButton.setIcon(QIcon(\"send.png\"))  \n",
    "        self.sendButton.setFixedSize(50, 50)     \n",
    "        self.sendButton.setObjectName(\"sendButton\")   \n",
    "\n",
    "        topLayout.addWidget(self.label)\n",
    "        bottomLayout.addWidget(self.inputTextEdit)  \n",
    "        bottomLayout.addWidget(self.sendButton)\n",
    "        outerLayout.addLayout(topLayout)  # Add topLayout to outerLayout\n",
    "        outerLayout.addWidget(self.outputTextEdit)\n",
    "        outerLayout.addLayout(bottomLayout)\n",
    "        disclaimer = QLabel(\"  get well soon... Made with  by First AI d Chatbot Team\")\n",
    "        disclaimer.setStyleSheet(\"font-size: 12px; color: #888;\")\n",
    "        outerLayout.addWidget(disclaimer)  \n",
    "       \n",
    "        def animateDisclaimer(self):\n",
    "            animation = QPropertyAnimation(self.disclaimer, b\"rotation\")\n",
    "            animation.setDuration(1000)\n",
    "            animation.setStartValue(0)\n",
    "            animation.setEndValue(5)\n",
    "            animation.setEasingCurve(Qt.CurveType.InOutQuad)\n",
    "            animation.start()\n",
    "            self.disclaimer.setText(\"Reminder: This chatbot provides First Aid advice only.\")\n",
    "        \n",
    "        # Set the main layout for the window\n",
    "        self.setLayout(outerLayout)\n",
    "\n",
    "        # Connect button click to function\n",
    "        self.sendButton.clicked.connect(self.processText)\n",
    "\n",
    "        # Apply CSS styling\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QWidget {\n",
    "                background-color: #000000; /* Dark black background */\n",
    "                font-family: Arial, sans-serif;\n",
    "                color: #FFFFFF; /* White text */\n",
    "            }\n",
    "            QLabel {\n",
    "                background-color: #000000;\n",
    "                border: 2px solid #FFFFFF; /* White border */\n",
    "                border-radius: 10px;\n",
    "                padding: 10px;\n",
    "                box-shadow: 0 4px 8px rgba(255, 255, 255, 0.2); /* White box shadow */\n",
    "                transition: all 0.3s ease;\n",
    "                font-size: 24px;\n",
    "                text-align: center;\n",
    "                font-weight: bold;\n",
    "                text-shadow: 2px 2px 4px rgba(255, 255, 255, 0.5); /* White text shadow */\n",
    "                background: radial-gradient(circle, rgba(0, 0, 0, 0) 0%, rgba(0, 0, 0, 0.5) 100%);\n",
    "            }\n",
    "            QLabel:hover {\n",
    "                transform: scale(1.05);\n",
    "                box-shadow: 0 8px 16px rgba(255, 255, 255, 0.3);\n",
    "            }\n",
    "            QTextEdit {\n",
    "                background-color: #000000; /* Black background */\n",
    "                border: 2px solid #FFFFFF;\n",
    "                border-radius: 5px;\n",
    "                padding: 8px;\n",
    "                box-shadow: 0 2px 4px rgba(255, 255, 255, 0.1); /* White box shadow */\n",
    "                transition: border-color 0.3s ease;\n",
    "                color: #FFFFFF; /* White text */\n",
    "            }\n",
    "            QTextEdit:focus {\n",
    "                border-color: #FFFFFF; /* White border on focus */\n",
    "            }\n",
    "            QPushButton#sendButton {\n",
    "                background-color: #000000; /* White button */\n",
    "                border: none;\n",
    "                border-radius: 5px;\n",
    "                color: #000000; /* Black text */\n",
    "                padding: 12px 28px;\n",
    "                text-align: center;\n",
    "                text-decoration: none;\n",
    "                display: inline-block;\n",
    "                font-size: 16px;\n",
    "                margin: 4px 2px;\n",
    "                cursor: pointer;\n",
    "                border-radius: 5px;\n",
    "                box-shadow: 0 4px 8px rgba(255, 255, 255, 0.2); /* White box shadow */\n",
    "                transition: background-color 0.3s, box-shadow 0.2s;\n",
    "                border-color: #FFFFFF; /* White border */\n",
    "            }\n",
    "            QPushButton#sendButton:hover {\n",
    "                background-color: #45a049;\n",
    "                box-shadow: 0 6px 12px rgba(255, 255, 255, 0.3);\n",
    "            }\n",
    "            QPushButton#sendButton:pressed {\n",
    "                background-color: #397a3c;\n",
    "                box-shadow: 0 3px 6px rgba(255, 255, 255, 0.3);\n",
    "            }\n",
    "            @media (max-width: 768px) {\n",
    "                QPushButton {\n",
    "                    padding: 10px 20px;\n",
    "                    font-size: 14px;\n",
    "                }\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "    def processText(self):\n",
    "        input_text = self.inputTextEdit.toPlainText()  \n",
    "        \n",
    "        processed_text = chat(input_text)\n",
    "        self.outputTextEdit.setPlainText(processed_text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    chat_gui = ChatGUI()\n",
    "    chat_gui.show()\n",
    "\n",
    "    sys.exit(app.exec_())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
